{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb06d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afcf1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES_FILE = \"names.txt\"\n",
    "TERM_TOK = \".\"\n",
    "CONTEXT_SIZE = 2\n",
    "SEED = 2147483647\n",
    "LAMBDA = 0.01  # l2 regularization strength\n",
    "LEARNING_RATE = 50\n",
    "NUM_EPOCHS = 100  # goes through the entire dataset this many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7473d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [line.strip() for line in pathlib.Path(NAMES_FILE).open(\"r\").readlines()]\n",
    "chars = [TERM_TOK] + sorted(list(set(\"\".join(words))))\n",
    "stoi = {s: i for i, s in enumerate(chars)}\n",
    "itos = chars\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e613231b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 2]), torch.Size([228146]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create trigram distribution\n",
    "def build_dataset(words: list[str]) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    X, y = [], []\n",
    "    context = [stoi[TERM_TOK]] * CONTEXT_SIZE\n",
    "    for word in words:\n",
    "        for c in word + TERM_TOK:\n",
    "            ix = stoi[c]\n",
    "            X.append(context)\n",
    "            y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    X = torch.tensor(X)\n",
    "    y = torch.tensor(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = build_dataset(words)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b22cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 27])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting method\n",
    "trigrams = torch.cat((X, y.view(-1, 1)), dim=1)\n",
    "N = torch.zeros((vocab_size,) * (CONTEXT_SIZE + 1), dtype=torch.long)\n",
    "unique_trigrams, counts = torch.unique(trigrams, dim=0, return_counts=True)\n",
    "N[torch.unbind(unique_trigrams, dim=1)] = counts\n",
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75374cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability distribution with add-1 smoothing\n",
    "P = (N + 1).float()  # add-1 smoothing\n",
    "P /= P.sum(dim=-1, keepdim=True)\n",
    "assert torch.allclose(P.sum(dim=-1), torch.ones((vocab_size,) * CONTEXT_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "507ab12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexzm.\n",
      "zoglkurkicqzktyhwevmzimjttainrlkfukzkktda.\n",
      "sfcxvpubjtbhrmgotzx.\n",
      "iczieqctvujkwptedogkkjemkmmsedguenkbvgynywftbspmhwcivgbvtahlvsu.\n",
      "dsdxxblnwglhpyiw.\n"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    context = [stoi[TERM_TOK]] * CONTEXT_SIZE\n",
    "    while True:\n",
    "        p = P[*context]\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(\"\".join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a084b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll=tensor(503516.8750)\n",
      "2.20699405670166\n"
     ]
    }
   ],
   "source": [
    "# calculate loss\n",
    "nll = -torch.sum(torch.log(P) * N)\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll / N.sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kamui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
