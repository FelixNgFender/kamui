{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b87e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "from typing import Literal\n",
    "import math\n",
    "import enum\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57027036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ModelType(enum.StrEnum):\n",
    "    CHAR_BIGRAM = \"char_bigram\"\n",
    "    WORD_MLP = \"word_mlp\"\n",
    "\n",
    "\n",
    "USE_ACCELERATOR = True\n",
    "TORCH_SEED = 2147483647\n",
    "SEED = 42\n",
    "INPUT_FILE = \"tinyshakespeare.txt\"\n",
    "MODEL_TYPE: ModelType = ModelType.CHAR_BIGRAM\n",
    "\n",
    "\n",
    "TRAIN_SPLIT = 0.9\n",
    "VAL_SPLIT = 0.1\n",
    "assert TRAIN_SPLIT + VAL_SPLIT == 1.0\n",
    "\n",
    "# hyperparams\n",
    "CONTEXT_SIZE = 8  # the maximum length of predictions\n",
    "EMBEDDING_SIZE = 24\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 5\n",
    "BATCH_SIZE = 64  # the number of independent sequences to process at once\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "\n",
    "device = (\n",
    "    torch.accelerator.current_accelerator()\n",
    "    if torch.accelerator.is_available() and USE_ACCELERATOR\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ef56be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5674, -0.2373],\n",
      "        [-0.0274, -1.1008],\n",
      "        [ 0.2859, -0.0296],\n",
      "        [-1.5471,  0.6049],\n",
      "        [ 0.0791,  0.9046],\n",
      "        [-0.4713,  0.7868],\n",
      "        [-0.3284, -0.4330],\n",
      "        [ 1.3729,  2.9334]])\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "print(x[0])  # (T, C)\n",
    "\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "xbow = torch.zeros_like(x)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, : t + 1]\n",
    "        xbow[b, t] = xprev.mean(dim=0)\n",
    "\n",
    "# equal-weighted aggregation\n",
    "xbow2 = wei @ x  # (T, T) @ (B, T, C) -(broadcast)-> (B, T, C)\n",
    "assert torch.allclose(xbow, xbow2)\n",
    "\n",
    "# variable-weight aggregation\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0.0, float(\"-inf\"))\n",
    "wei = wei.softmax(dim=1)\n",
    "xbow3 = wei @ x\n",
    "assert torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a998e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[2., 9.],\n",
      "        [2., 7.],\n",
      "        [4., 5.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / a.sum(dim=1, keepdim=True)\n",
    "print(a)\n",
    "b = torch.tensor([[2.0, 9.0], [2.0, 5.0], [8.0, 1.0]])\n",
    "result = torch.zeros_like(b)\n",
    "for i in range(b.shape[0]):\n",
    "    result[i] = b[: i + 1].mean(dim=0)\n",
    "print(result)\n",
    "\n",
    "torch.allclose(a @ b, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976e26bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn((B, T, C))\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "print(tril)\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0.0, float(\"-inf\"))\n",
    "wei = wei.softmax(dim=1)\n",
    "xbow3 = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c7934f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4., 1., 2., 3., 0., 1., 4., 0., 1., 4., 1., 3., 1., 1., 4.],\n",
      "        [0., 1., 0., 3., 4., 3., 1., 4., 1., 3., 4., 4., 1., 2., 4., 3.],\n",
      "        [3., 4., 0., 0., 4., 4., 1., 3., 1., 3., 4., 4., 4., 0., 0., 1.],\n",
      "        [2., 0., 0., 0., 1., 0., 4., 2., 4., 3., 2., 2., 0., 2., 3., 3.]])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]])\n",
      "tensor([[23., 60., 44., 55., 67., 81., 52., 67.],\n",
      "        [30., 69., 53., 66., 78., 72., 69., 65.],\n",
      "        [28., 68., 48., 62., 73., 75., 64., 66.],\n",
      "        [25., 39., 49., 58., 49., 48., 45., 52.]])\n",
      "tensor([[23., 60., 44., 55., 67., 81., 52., 67.],\n",
      "        [30., 69., 53., 66., 78., 72., 69., 65.],\n",
      "        [30., 69., 53., 66., 78., 72., 69., 65.],\n",
      "        [30., 69., 53., 66., 78., 72., 69., 65.]])\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 2, 4, 16\n",
    "D_head = 8\n",
    "embeddings = torch.randint(0, 5, (B, T, C)).float()\n",
    "W_q = torch.randint(0, 5, (C, D_head)).float()\n",
    "W_k = torch.randint(0, 5, (C, D_head)).float()\n",
    "W_v = torch.randint(0, 5, (C, D_head)).float()\n",
    "queries = embeddings @ W_q  # (B, T, D_head)\n",
    "keys = embeddings @ W_k  # (B, T, D_head)\n",
    "values = embeddings @ W_v  # (B, T, D_head)\n",
    "\n",
    "attn_scores = queries @ keys.transpose(-2, -1)  # (B, T, D_head) @ (B, D_head, T) -> (B, T, T)\n",
    "attn_scores = attn_scores / torch.sqrt(torch.tensor(D_head, dtype=torch.float32))  # normalize\n",
    "tril = torch.tril(torch.ones(T, T))  # mask out future tokens\n",
    "attn_scores = attn_scores.masked_fill(tril == 0.0, float(\"-inf\"))\n",
    "attn_weights = F.softmax(attn_scores, dim=-1)  # (B, T, T)\n",
    "residuals = attn_weights @ values  # (B, T, T) @ (B, T, D_head) -> (B, T, D_head)\n",
    "print(embeddings[0])\n",
    "print(attn_weights[0])\n",
    "print(values[0])\n",
    "print(residuals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb9fb160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.1925e-03, -6.0443e-01, -6.5695e-01, -4.3440e-02,  5.8751e-01,\n",
      "         -7.3220e-01, -4.6700e-01,  2.0095e-01, -5.4697e-01, -4.9193e-01,\n",
      "          2.4311e-01,  5.2821e-01, -3.1823e-01, -4.9768e-01, -5.8761e-01,\n",
      "         -3.6939e-01],\n",
      "        [-7.8378e-02, -3.4855e-01, -3.1900e-01, -5.0265e-01,  3.3814e-01,\n",
      "         -4.7783e-01, -6.1466e-01,  9.3785e-02, -1.0540e-01, -4.1946e-01,\n",
      "          4.3377e-01,  6.1648e-01, -4.4797e-01, -6.4522e-01, -4.9924e-01,\n",
      "          8.0813e-02],\n",
      "        [-3.4285e-01, -4.2789e-01, -1.5630e-01, -3.9100e-01,  1.4745e-01,\n",
      "         -4.0785e-01, -4.9640e-01,  2.5882e-02, -8.4196e-02, -1.9822e-01,\n",
      "          4.4566e-01,  2.7950e-01, -3.9456e-01, -6.4231e-01, -4.5462e-01,\n",
      "         -1.0927e-01],\n",
      "        [-4.4342e-01, -3.8915e-01, -1.1667e-01, -4.8522e-01,  3.4610e-01,\n",
      "         -2.8422e-01, -3.3227e-01,  6.2355e-02, -5.4839e-02, -3.4362e-01,\n",
      "          3.9218e-01,  8.1700e-02, -4.9806e-01, -5.2871e-01, -2.5724e-01,\n",
      "         -2.0421e-01],\n",
      "        [-4.0587e-01, -2.2303e-01, -7.1758e-02, -6.0219e-01,  3.4601e-01,\n",
      "          7.3179e-02, -2.9996e-01,  2.0580e-01, -1.1042e-01, -1.7036e-01,\n",
      "          4.6808e-01, -1.3858e-01, -3.8359e-01, -4.3003e-01,  2.4487e-01,\n",
      "         -4.7825e-02],\n",
      "        [-3.9228e-01, -2.0845e-01,  2.0991e-02, -5.7305e-01,  3.4866e-01,\n",
      "          1.0586e-01, -2.1872e-01,  1.5182e-01, -5.6844e-02, -1.9347e-01,\n",
      "          4.3885e-01, -6.8116e-02, -3.8711e-01, -3.0082e-01,  2.0781e-01,\n",
      "         -3.7264e-02],\n",
      "        [-2.6544e-01, -2.0496e-01,  9.9368e-03, -3.9479e-01,  3.5948e-01,\n",
      "          7.3130e-02, -1.1044e-01,  1.8667e-01, -1.7490e-01, -1.2612e-01,\n",
      "          3.0599e-01,  8.6223e-02, -2.2361e-01, -1.3922e-01,  1.3280e-01,\n",
      "         -7.2283e-02],\n",
      "        [-1.8882e-01, -1.8191e-01, -4.8594e-04, -3.0030e-01,  2.9820e-01,\n",
      "          1.0221e-01, -2.1145e-02,  2.2747e-01, -1.6326e-01, -9.1227e-02,\n",
      "          1.9181e-01,  5.4796e-02, -8.1753e-02, -1.4323e-02,  1.0193e-01,\n",
      "         -8.5753e-02]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 32\n",
    "head_size = 16\n",
    "x = torch.randn((B, T, C))\n",
    "W_q = nn.Linear(C, head_size, bias=False)\n",
    "W_k = nn.Linear(C, head_size, bias=False)\n",
    "W_v = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "x_q = W_q(x)  # (B, T, C) @ (C, head_size) -> (B, T, head_size)\n",
    "x_k = W_k(x)  # same\n",
    "x_v = W_v(x)  # same\n",
    "\n",
    "attn = x_q @ x_k.transpose(-2, -1) / head_size**0.5  # (B, T, T)\n",
    "mask = torch.tril(torch.ones(T, T))\n",
    "attn = attn.masked_fill(mask == 0.0, float(\"-inf\"))\n",
    "attn = attn.softmax(dim=-1)\n",
    "out = attn @ x_v  # (B, T, T) @ (B, T, head_size) -> (B, T, head_size)\n",
    "\n",
    "print(out[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
